HashMap在高并发情况下存在的另一个问题：死链。
重现死链场景：
    用10万个线程 采用均匀的Key往同一个 HashMap中放置不同的自定义对象EasyCoding，然后查看内存中的对象数量。
    预期内存中应该有10万个对象，但是实际只存在98908个对象 - aka 丢失了1092个对象。
    原因：在对象赋值阶段可能会产生覆盖。
    进一步验证可能的对象丢失 - 手段：手动进行 垃圾回收；
    结果：对象数量变成了 90853, aka 又丢失了 8055个对象；
    具体原因：垃圾回收动作回收了 在数据迁移过程中,丢失了引用的对象；
    而剩余的对象，都被 Map的强引用所持有，不会被GC回收。

分析死链问题：
构造场景：
    启动10万个线程，以 System.nanoTime()返回的Long值作为 Key,
    以自定义的对象 EasyCoding作为Value【运行环境 JDK1.7】;
示例代码： HashMapEndlessLoop.java
结果：
    当对象计数达到1万个左右时(怎么查看内存中的对象数量？),load呈阶梯式上升；
    CPU使用率上升到 304%, 什么导致了如此之高的CPU使用率呢？
    手段：通过检测工具(什么样的工具？)查看线程；
        Thread-10799 & Thread-12296
        特征：
            1 一直处在 RUNNING的状态；
            2 已经持续运行了18分钟； - 推测死链已经形成了，所以才会有如此夸张的资源消耗

    查看具体执行什么命令时引发了问题 - 手段：jstack命令查看线程信息；
        Thread-10799
            put() 601行
        Thread-12296
            transfer() 494行

    这两个方法中都有 对哈希桶链表的遍历访问操作。
    put():
        通过循环 来 提取某一个哈希桶中的所有元素，然后再倒序地逐一插入到新表中；
    transfer():
        遍历访问 某一个哈希桶中的所有元素，以决定 是要新增一个新的元素，还是覆盖掉已经存在的Key的value值。
    所谓死链，就是在 哈希桶的链表中出现了环；

死链是怎么产生的？
代码（transfer()方法）：
    while(null != e) {
        Entry<K, V> next = e.next;
        e.next = newTable[5883]; // step2
        newTable[5883] = e; // step3
        e = next;
    }
解释：在因为扩容而进行的数据迁移时，Key在同一个slot上的链表上进行遍历时，step2与step3之间形成了 数据相互覆盖的情况。
死链形成的前提：
    #1 先前不存在死链的slot上的节点一定可以按照顺序遍历完成； - 因为e, next都是 线程局部变量。也正因如此, while循环其实会正常退出
    #2 table数组 是多线程所共享的变量；
    #3 当put()、get()、transfer()这三个方法 运行到了 包含死链的slot上时，CPU使用率i聚会飙高。

recap
死链形成的根源：
    table中的 Entry链表是多线程共享的, 因此 Entry的next可能会被多个线程 并发地修改。从而导致：
    #1 对象丢失；
    #2 两个对象之间互链；
    #3 对象自己互链。