实践：相比于 HashMap，优先推荐使用 ConcurrentHashMap;
原因：两者性能相差无几，但是后者解决了高并发下的线程安全问题。

HashMap潜在的问题：
1 死链问题；
2 扩容时可能引起数据丢失；

问题场景复现：
    用法：程序中 init()方法初始化了 static的HashMap集合对象，从数据库中获取数据到集合中。
    分析：如果应用启动过程中，只是单线程调用了一次初始化方法，应该能够正常存取数据；
    可如果 init()由于某种原因被执行了两次，就可能引起 HashMap死链的情况。
    原理：HashMap中出现了环形链表 - 这会使得 get()的操作进入无限循环中。
解决方案：
    1 使用 ConcurrentHashMap 来 替换 HashMap；
    2 使用 Collections.synchronizedMap()把 hashmap对象 包装成 同步集合；
    3 对init()方法添加同步的约束，避免多个线程同时执行init()

案例2：CPU使用率100%, 大量请求超时（监控平台）；
方案1：对服务器进行扩容 - 没管用
方案2：jstack命令查看？？？
    大量 RUNNABLE状态的线程都在执行 HashMap的put与get操作；
    基本判定与 HashMap的get、put操作相关。

HashMap中三个与存储相关的概念：
1 table - 用于存储所有的节点数据；
2 slot - 哈希槽，也就是数组中的一个方格 table[i]；
3 bucket - 哈希桶，由table[i]位置上所有元素形成的表/树的集合。

hashmap's size = 所有哈希桶中的元素的总和。

死链问题来源： JDK1.7中的 HashMap源码；

------
HashMap 新增元素的过程：
    put()
    addEntry()
    createEntry()
    新添加的元素直接放在 slot槽上，使新添加的元素 能够在下次提取时，可以被更快地访问到。
    分析：如果两个线程同时执行的话，在createEntry()方法中，会出现 线程之间的赋值覆盖 - 这就是对象丢失的原因。

usage demo：HashMapSimpleResize

与扩容相关的概念：
#1 length - table数组的长度；
#2 size - 通过put方法添加到 HashMap中的所有元素的个数
#3 hashCode - Object.hashCode()返回的int值。 要求：尽可能数学上离散分布
#4 hash - hashCode与 当前集合的table.length 进行位运算的结果，用来确定hash槽的位置

扩容机制：
当容器中的元素数量 > 默认容量大小 * 负载因子时，就会进行扩容。

resize操作：
    在第4次元素复制完成后，哈希桶内的元素被逆序排列到新表中。

    为什么会逆序排列呢？
    resize() + transfer()数据迁移 [JDK7]

    分析：
    #1 transfer()数据迁移方法，如果数组非常大，那么：方法会非常消耗资源；
    #2 多线程条件下，当前线程迁移过程中，其他线程新增的元素可能就已经落到 已经遍历过的哈希槽中了；
    #3 遍历完成后，table的数组引用 会指向newTable - 这时新增元素就会丢失，然后被作为垃圾回收。

    如果resize完成, aka, 执行了 table = newTable, 则：
        后继的元素 就可以在新的表上执行插入操作。
    但如果多个线程同时执行resize操作, aka, 每个线程 都会 new Entry[newCapacity].
    这是线程的局部数组对象，不同线程之间是不可见的。

    在迁移完成后，resize的线程就会赋值给 table这个线程共享变量。
    结果：覆盖其他线程的操作 - 在新的表中插入的对象就会被丢弃掉。

总结：
HashMap在高并发场景下，新增对象丢失的原因有：
    #1 并发赋值时，值被覆盖；
    #2 在已经遍历的区间中新增的元素会丢失；
    #3 “新的表”被覆盖???
    #4 在并发的条件下，迁移过程中，next被提前置为null???
总之， HashMap在高并发情况下，有很多机会发生数据丢失。且不易察觉
======
HashMap在高并发情况下存在的另一个问题：死链。
重现死链场景：
    用10万个线程 采用均匀的Key往同一个 HashMap中放置不同的自定义对象EasyCoding，然后查看内存中的对象数量。
    预期内存中应该有10万个对象，但是实际只存在98908个对象 - aka 丢失了1092个对象。
    原因：在对象赋值阶段可能会产生覆盖。
    进一步验证可能的对象丢失 - 手段：手动进行 垃圾回收；
    结果：对象数量变成了 90853, aka 又丢失了 8055个对象；
    具体原因：垃圾回收动作回收了 在数据迁移过程中,丢失了引用的对象；
    而剩余的对象，都被 Map的强引用所持有，不会被GC回收。

分析死链问题：
构造场景：
    启动10万个线程，以 System.nanoTime()返回的Long值作为 Key,
    以自定义的对象 EasyCoding作为Value【运行环境 JDK1.7】;
示例代码： HashMapEndlessLoop.java
结果：
    当对象计数达到1万个左右时(怎么查看内存中的对象数量？),load呈阶梯式上升；
    CPU使用率上升到 304%, 什么导致了如此之高的CPU使用率呢？
    手段：通过检测工具(什么样的工具？)查看线程；
        Thread-10799 & Thread-12296
        特征：
            1 一直处在 RUNNING的状态；
            2 已经持续运行了18分钟； - 推测死链已经形成了，所以才会有如此夸张的资源消耗

    查看具体执行什么命令时引发了问题 - 手段：jstack命令查看线程信息；
        Thread-10799
            put() 601行
        Thread-12296
            transfer() 494行

    这两个方法中都有 对哈希桶链表的遍历访问操作。
    put():
        通过循环 来 提取某一个哈希桶中的所有元素，然后再倒序地逐一插入到新表中；
    transfer():
        遍历访问 某一个哈希桶中的所有元素，以决定 是要新增一个新的元素，还是覆盖掉已经存在的Key的value值。
    所谓死链，就是在 哈希桶的链表中出现了环；

知识卡： Long值的hashCode()是怎么计算的？
注：Integer的hashCode()是 Integer值自身；
步骤：
    1 获取到Long值的二进制数值；
    2 对1中得到的二进制数值右移32位；
    3 对 1中得到的二进制数值 与 2中得到的二进制数值 进行异或处理，得到新的二进制数值；
    4 对 3中得到的二进制数值，进行 int的强制类型转换 - 等同于高位被截断；
为什么使用这种算法（异或操作） 来 计算Long值的hashCode值呢？
答：避免冲突，有助于泊松分布(😳)

死链是怎么产生的？
代码（transfer()方法）：
    while(null != e) {
        Entry<K, V> next = e.next;
        e.next = newTable[5883]; // step2
        newTable[5883] = e; // step3
        e = next;
    }
解释：在因为扩容而进行的数据迁移时，Key在同一个slot上的链表上进行遍历时，step2与step3之间形成了 数据相互覆盖的情况。
死链形成的前提：
    #1 先前不存在死链的slot上的节点一定可以按照顺序遍历完成； - 因为e, next都是 线程局部变量。也正因如此, while循环其实会正常退出
    #2 table数组 是多线程所共享的变量；
    #3 当put()、get()、transfer()这三个方法 运行到了 包含死链的slot上时，CPU使用率i聚会飙高。

死链形成的根源：
    table中的 Entry链表是多线程共享的, 因此 Entry的next可能会被多个线程 并发地修改。从而导致：
    #1 对象丢失；
    #2 两个对象之间互链；
    #3 对象自己互链。

JDK7中的代码实现为：先扩容，然后进行新元素的添加操作；
而JDK8中是增加元素之后，再进行扩容。

JDK7中实现的特征：
    从头节点开始，来操作数据迁移；aka, 头插法
JDK8中实现的特征：
    采用对旧链表的头尾节点引用，从而保证“有序性”？？？


