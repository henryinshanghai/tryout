HashMap在 高并发情况 下 存在的 另一个问题：死链。

===
重现死链场景：
    用 10万个线程 采用 均匀的Key 往 同一个 HashMap中 放置 不同的 自定义对象EasyCoding，然后 查看 内存中的对象数量。
    观察：预期 内存中 应该有 10万个对象，但是 实际 只存在 98908个对象 - aka 丢失了 1092个对象。
    原因：在 对象赋值阶段 可能会 产生覆盖。

    进一步验证 可能的对象丢失 - 手段：手动进行 垃圾回收；
    结果：对象数量 变成了 90853, aka 又丢失了 8055个对象；
    具体原因：
        ① 垃圾回收动作 回收了 在 数据迁移过程 中 那些个 丢失了引用的对象；
        ② 而 剩余的对象，都被 Map的强引用 所持有，不会 被GC回收。

===
分析死链问题：
构造场景：
    启动 10万个线程，以 System.nanoTime()返回的Long值 作为 Key,
    以 自定义的对象 EasyCoding 作为 Value【运行环境 JDK1.7】;
示例代码： HashMapEndlessLoop.java
结果：
    当 对象计数 达到1万个左右 时(怎么查看内存中的对象数量？), load 呈阶梯式上升；
    CPU使用率 上升到 304%, 什么 导致了 如此之高的CPU使用率呢？
    手段：通过 检测工具(什么样的工具？)查看线程；
        Thread-10799 & Thread-12296
        特征：
            1 一直处在 RUNNING的状态；
            2 已经 持续运行了 18分钟； - 推测 死链 已经形成了，所以才会有 如此夸张的资源消耗

    查看 具体执行什么命令时 引发了问题 - 手段：jstack命令 查看线程信息；
        Thread-10799
            put() 601行
        Thread-12296
            transfer() 494行

    这两个方法中都有 对 哈希桶链表 的 遍历访问操作。
    ① put():
        通过循环 来 提取某一个哈希桶中 的所有元素，然后再 倒序地 逐一插入到新表中；
    ② transfer():
        遍历访问 某一个哈希桶中的所有元素，以决定 是要 新增一个新的元素，还是 覆盖掉 已经存在的Key的value值。
    所谓 死链，就是在 哈希桶的链表中 出现了环；

===
死链是怎么产生的？
代码（transfer()方法）：
    while(null != e) {
        Entry<K, V> next = e.next;
        e.next = newTable[5883]; // step2
        newTable[5883] = e; // step3
        e = next;
    }
解释：在 因为扩容而进行的数据迁移 时，Key在 同一个slot上的链表上 进行遍历 时，step2与step3之间 形成了 数据相互覆盖 的情况。
死链形成的前提：
    #1 先前不存在死链的slot上的节点 一定可以 按照顺序 遍历完成； - 因为e, next都是 线程局部变量。也正因如此, while循环 其实会正常退出
    #2 table数组 是 多线程 所共享的变量；
    #3 当 put()、get()、transfer()这三个方法 运行到了 包含死链的slot上 时，CPU使用率 就会飙高。

===
死链形成的根源：
    table中的 Entry链表 是 多线程共享的, 因此 Entry的next 可能会 被多个线程并发地修改。从而导致：
    #1 对象丢失；
    #2 两个对象之间 互链；
    #3 对象自己互链。